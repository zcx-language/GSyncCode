_target_: src.models.screenshootresilient.ScreenShootResilient

region_selector:
  _target_: src.models.region_selectors.gradient_based.SobelBasedRegionSelector
  # _target_: src.models.region_selectors.center_based.CenterBasedRegionSelector
  size: 128 # the same size of qrcode
  stride: 16

encoder:
  # _target_: src.models.encoders.invisible_markers_encoder.InvisibleMarkersEncoder
  # ckpt_path: /home/chengxin/Project/ScreenShootResilient/src/models/encoders/inv_encoder0401010848299.pt
  _target_: src.models.encoders.haar_encoder.HaarEncoder2
  # ckpt_path: /home/chengxin/Project/ScreenShootResilient/src/models/encoders/haar2_encoder0403192533299.pt
  # _target_: src.models.encoders.inv_encoder.InvEncoder
  # n_inv_blocks: 8
  # _target_: src.models.encoders.unet_encoder.UNetEncoder
  # _target_: src.models.encoders.trans_encoder.TransEncoder
  # _target_: src.models.encoders.no_encoder.NoEncoder
  # _target_: src.models.encoders.mask_encoder.MaskEncoderHaarUNet


decoder:
  _target_: src.models.decoders.invisible_markers_decoder.InvisibleMarkersDecoder
  # ckpt_path: /home/chengxin/Project/ScreenShootResilient/src/models/decoders/inv_decoder0401010848299.pt
  # ckpt_path: /home/chengxin/Project/ScreenShootResilient/src/models/decoders/dmtx_inv_decoder0408093649299.pt
  # _target_: src.models.decoders.haar_decoder.HaarDecoder2
  # in_channels: 3
  # out_channels: 1
  # _target_: src.models.decoders.inv_decoder.InvDecoder
  # in_channels: 3
  # out_channels: 1
  # _target_: src.models.decoders.stn_decoder.STNDecoder
  # input_size: [3, 256, 256]
  # out_channels: 1
  # num_stn: 1
  # _target_: src.models.decoders.unet_decoder.UNetDecoder
  # _target_: src.models.decoders.trans_decoder.TransDecoder


discriminator:
  _target_: src.models.discriminators.nlayer_discriminator.NLayerDiscriminator
  input_nc: 3

# augmenter:
#   _target_: src.models.augmenters.pimog_augmenter.PIMoGAugmenter
#   perspective_scale: 0.5
#   perspective_p: 1.
#   illumination_p: 1.
#   moire_weight_bound: 0.15
#   moire_p: 1.
#   noise_std: 0.01
#   noise_p: 1.
augmenter:
  _target_: src.models.augmenters.augmenter.Augmenter
  aug_dict:
    # perspective5:
    #   _target_: src.models.augmenters.random_perspective.RandomPerspective
    #   distortion_scale: 0.5
    #   resample: nearest
    #   p: 1.
    #   sampling_method: basic
    #   padding_mode: border
    # perspective4:
    #   _target_: src.models.augmenters.random_perspective.RandomPerspective
    #   distortion_scale: 0.4
    #   resample: nearest
    #   p: 1.
    #   sampling_method: basic
    #   padding_mode: border
    perspective:
      _target_: src.models.augmenters.random_perspective.RandomPerspective
      _partial_: True
      # distortion_scale: 0.3
      resample: nearest
      p: 1.
      sampling_method: basic
      padding_mode: border
      distortion_scale_bound: 0.4
    # perspective2:
    #   _target_: src.models.augmenters.random_perspective.RandomPerspective
    #   distortion_scale: 0.2
    #   resample: nearest
    #   p: 1.
    #   sampling_method: basic
    #   padding_mode: border
    # perspective1:
    #   _target_: src.models.augmenters.random_perspective.RandomPerspective
    #   distortion_scale: 0.1
    #   resample: nearest
    #   p: 1.
    #   sampling_method: basic
    #   padding_mode: border
    # illumination3:
    #   # _target_: src.models.augmenters.illumination.Illumination
    #   # p: 0.9
    #   _target_: kornia.augmentation.ColorJitter
    #   brightness: 0.3
    # illumination2:
    #   _target_: kornia.augmentation.ColorJitter
    #   brightness: 0.2
    # illumination1:
    #   _target_: kornia.augmentation.ColorJitter
    #   brightness: 0.1
    # moire13:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.13
    #   p: 0.9
    # moire12:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.12
    #   p: 0.9
    # moire11:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.11
    #   p: 0.9
    # moire10:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.10
    #   p: 0.9
    # moire09:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.09
    #   p: 0.9
    # moire08:
    #   _target_: src.models.augmenters.moire.Moire
    #   weight_bound: 0.08
    #   p: 0.9
    # blur10:
    #   _target_: kornia.augmentation.RandomGaussianBlur
    #   kernel_size: [5, 5]
    #   # 0.3*((ksize-1)*0.5 - 1) + 0.8
    #   sigma: [1., 1.]
    #   p: 0.9
    # blur09:
    #   _target_: kornia.augmentation.RandomGaussianBlur
    #   kernel_size: [5, 5]
    #   # 0.3*((ksize-1)*0.5 - 1) + 0.8
    #   sigma: [0.9, 0.9]
    #   p: 0.9
    # blur08:
    #   _target_: kornia.augmentation.RandomGaussianBlur
    #   kernel_size: [3, 3]
    #   # 0.3*((ksize-1)*0.5 - 1) + 0.8
    #   sigma: [0.8, 0.8]
    #   p: 0.9
    # blur07:
    #   _target_: kornia.augmentation.RandomGaussianBlur
    #   kernel_size: [3, 3]
    #   # 0.3*((ksize-1)*0.5 - 1) + 0.8
    #   sigma: [0.7, 0.7]
    #   p: 0.9
    # blur06:
    #   _target_: kornia.augmentation.RandomGaussianBlur
    #   kernel_size: [3, 3]
    #   # 0.3*((ksize-1)*0.5 - 1) + 0.8
    #   sigma: [0.6, 0.6]
    #   p: 0.9
    # noise4:
    #   _target_: kornia.augmentation.RandomGaussianNoise
    #   mean: 0.0
    #   std: 0.04
    # noise3:
    #   _target_: kornia.augmentation.RandomGaussianNoise
    #   mean: 0.0
    #   std: 0.03
    # noise2:
    #   _target_: kornia.augmentation.RandomGaussianNoise
    #   mean: 0.0
    #   std: 0.02
    # noise1:
    #   _target_: kornia.augmentation.RandomGaussianNoise
    #   mean: 0.0
    #   std: 0.01
    # jpeg95:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 95
    #   p: 0.9
    # jpeg90:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 90
    #   p: 0.9
    # jpeg85:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 85
    #   p: 0.9
    # jpeg80:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 80
    #   p: 0.9
    # jpeg75:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 75
    #   p: 0.9
    # jpeg70:
    #   _target_: src.models.augmenters.DiffJPEG.DiffJPEG.DiffJPEG
    #   height: 256
    #   width: 256
    #   differentiable: True
    #   quality: 70
    #   p: 0.9

loss_func:
  # weighted_yuv_loss:  # Decrease color distortion
  #   _target_: src.models.loss_funcs.weighted_yuv_loss.WeightedYUVLoss
  #   weights: [1, 10, 10]
  weighted_rgb_loss:
    _target_: src.models.loss_funcs.weighted_rgb_loss.WeightedRGBLoss
    dist_type: l1

  lpips_loss:  # Decrease texture distortion by embedding in texture-rich space
    _target_: lpips.lpips.LPIPS
    net: vgg

  # haar_loss:
  #   _target_: src.models.loss_funcs.haar_loss.RGBHaarLoss
  #   image_size: [64, 64]
  #   freq_weight: [1., 0.5, 0.5, 0.5]    # weights for ll, lh, hl, hh
  #   dist_type: l1
  #   edge_gain: 0.

  # decode_loss:
  #   _target_: torch.nn.functional.binary_cross_entropy_with_logits
    # _target_: torch.nn.BCEWithLogitsLoss
    # pos_weight:  # ratio of negative to positive samples
    #   _target_: torch.Tensor
    #   data: [0.5]

loss_cfg:
  vis_weight: 1.
  gen_weight: 1.
  encode_weight: 0.01
  encode_decay: 3
  decode_weight: 1.

model_cfg:
  geometric_sync: True # Set to `True` to make qrcode_gt warped the same perspective of container
  alpha: 1.   # weight for host
  beta: 1.    # weight for residual
  embed_edge: False
  mask_residual: True
  code_type: dmtx
